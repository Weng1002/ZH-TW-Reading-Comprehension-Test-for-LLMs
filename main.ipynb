{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas openpyxl\n",
    "!pip install bitsandbytes==0.38.1\n",
    "!pip install torch transformers==4.31.0 peft==0.4.0 sentencepiece bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將 Datasets 轉成 LoRA 的訓練的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已將 AI1000.xlsx 轉換為 test.json\n"
     ]
    }
   ],
   "source": [
    "# xlsx_to_json.py\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def xlsx_to_json(xlsx_path, json_path):\n",
    "    df = pd.read_excel(xlsx_path)\n",
    "\n",
    "    data_list = []\n",
    "    for idx, row in df.iterrows():\n",
    "        article = str(row[\"文章\"]).strip()\n",
    "        question = str(row[\"問題\"]).strip()\n",
    "        option1 = str(row[\"選項1\"]).strip()\n",
    "        option2 = str(row[\"選項2\"]).strip()\n",
    "        option3 = str(row[\"選項3\"]).strip()\n",
    "        option4 = str(row[\"選項4\"]).strip()\n",
    "        correct_ans = str(row[\"正確答案\"]).strip()  # 假設是 \"1\" \"2\" \"3\" \"4\"\n",
    "\n",
    "        # 組成 input 區塊\n",
    "        combined_input = (\n",
    "            f\"【文章】{article}\\n\"\n",
    "            f\"【問題】{question}\\n\"\n",
    "            f\"【選項】\\n\"\n",
    "            f\"1) {option1}\\n\"\n",
    "            f\"2) {option2}\\n\"\n",
    "            f\"3) {option3}\\n\"\n",
    "            f\"4) {option4}\"\n",
    "        )\n",
    "\n",
    "        # 建立一筆 dict\n",
    "        one_sample = {\n",
    "            \"instruction\": \"請仔細閱讀以下文章，理解內容後，依據邏輯分析，逐步排除錯誤選項，並最終選擇最正確的答案。只需要回覆正確的數字選項 (1, 2, 3, 或 4)。\",\n",
    "            \"input\": combined_input,\n",
    "            \"output\": correct_ans\n",
    "        }\n",
    "        data_list.append(one_sample)\n",
    "\n",
    "    # 寫入 JSON\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data_list, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    xlsx_path = \"AI.xlsx\"   # 你的原始資料\n",
    "    json_path = \"train.json\"\n",
    "    xlsx_to_json(xlsx_path, json_path)\n",
    "    print(f\"已將 {xlsx_path} 轉換為 {json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "def generate_prompt(text):\n",
    "    return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained('shibing624/chinese-alpaca-plus-7b-hf')\n",
    "model = LlamaForCausalLM.from_pretrained('shibing624/chinese-alpaca-plus-7b-hf').half().cuda()\n",
    "model.eval()\n",
    "\n",
    "text = '为什么天空是蓝色的？'\n",
    "prompt = generate_prompt(text)\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt').to('cuda')\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=128,\n",
    "        temperature=1,\n",
    "        top_k=40,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.15\n",
    "    ).cuda()\n",
    "output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(output.replace(text, '').strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始微調的code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetune_lora.py\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    LlamaTokenizer,\n",
    "    LlamaForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# ============ A) 超參數設定 ============\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LR = 1e-4\n",
    "MAX_LENGTH = 256\n",
    "OUTPUT_DIR = \"lora-out\"  # 微調結果(LoRA)輸出位置\n",
    "\n",
    "BASE_MODEL = \"shibing624/chinese-alpaca-plus-7b-hf\"\n",
    "TRAIN_FILE = \"train.json\"  # 你的自訂資料集檔名\n",
    "\n",
    "# ============ B) 讀取 JSON & 格式化資料 ============\n",
    "def load_data(json_path):\n",
    "    \"\"\"讀取 train.json，每筆應包含 instruction, input, output三欄\"\"\"\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data_list = json.load(f)\n",
    "    return data_list\n",
    "\n",
    "def format_example(example):\n",
    "    \"\"\"\n",
    "    - instruction: str\n",
    "    - input: str (可能是空)\n",
    "    - output: str (模型要學習產生的回答)\n",
    "    回傳 prompt, output_text\n",
    "    \"\"\"\n",
    "    instruction = example[\"instruction\"]\n",
    "    input_text = example.get(\"input\", \"\")\n",
    "    output_text = example[\"output\"]\n",
    "\n",
    "    if input_text.strip():\n",
    "        prompt = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input_text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "    return prompt, output_text\n",
    "\n",
    "def tokenize_fn(example):\n",
    "    \"\"\"\n",
    "    把 prompt + output_text 做 tokenize，同時對 prompt 部分做 label = -100 (不計算 loss)\n",
    "    \"\"\"\n",
    "    prompt, answer = format_example(example)\n",
    "    full_text = prompt + answer\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        full_text,\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    # 計算 prompt 的 token 長度\n",
    "    prompt_len = len(tokenizer(prompt, truncation=True, max_length=MAX_LENGTH)[\"input_ids\"])\n",
    "    labels = encoding[\"input_ids\"].copy()\n",
    "\n",
    "    # 將 prompt 的部分 label 設成 -100\n",
    "    for i in range(prompt_len):\n",
    "        if i < MAX_LENGTH:\n",
    "            labels[i] = -100\n",
    "\n",
    "    encoding[\"labels\"] = labels\n",
    "    return encoding\n",
    "\n",
    "# ============ C) 載入 tokenizer & base model & LoRA 設定 ============\n",
    "print(\"Loading base model & tokenizer...\")\n",
    "tokenizer = LlamaTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "# LLaMA/Alpaca 預設沒有 pad token，可自行加\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(\"[PAD]\")\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    load_in_8bit=True,  # 8-bit量化，節省顯存\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# LoRA 配置\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # LLaMA 常見設定\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# 讓 embeddings 大小配上新增的 [PAD] token\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# 包裝成PEFT模型\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# ============ D) 準備 Dataset ============\n",
    "print(\"Loading dataset...\")\n",
    "train_data = load_data(TRAIN_FILE)\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "train_dataset = train_dataset.map(tokenize_fn)\n",
    "\n",
    "# (若有 validation set，可同樣做 valid_dataset)\n",
    "# valid_data = load_data(\"valid.json\")\n",
    "# valid_dataset = Dataset.from_list(valid_data).map(tokenize_fn)\n",
    "\n",
    "# ============ E) Trainer 設定 ============\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=2,      # 或者 2, 視顯存而定\n",
    "    gradient_accumulation_steps=4,      # 等效於 batch_size=8\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    fp16=True,\n",
    "    logging_steps=5,\n",
    "    save_steps=200,\n",
    "    save_total_limit=5,\n",
    "    disable_tqdm=False,                 # 顯示tqdm\n",
    "    logging_strategy=\"steps\",           # 每steps都log\n",
    "    report_to=[],                       # 不用wandb\n",
    ")\n",
    "\n",
    "# ============ F) 建立 Trainer & 開始微調 ============\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    # eval_dataset=valid_dataset,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"Saving LoRA adapter...\")\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "print(\"LoRA fine-tune is done! The adapter is saved at:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "微調"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetune_lora.py\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import gc\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    LlamaForCausalLM,\n",
    "    LlamaTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# --------------- A) 超參數 ---------------\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 5\n",
    "LR = 5e-5\n",
    "MAX_LENGTH = 1024\n",
    "OUTPUT_DIR = \"lora-out\"\n",
    "\n",
    "# --------------- B) 讀取 JSON 資料 ---------------\n",
    "def load_data(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def format_example(example):\n",
    "    \"\"\"\n",
    "    - instruction: str\n",
    "    - input: str (可能是空)\n",
    "    - output: str (模型要學習產生的回答)\n",
    "    回傳 prompt, output_text\n",
    "    \"\"\"\n",
    "    instruction = example[\"instruction\"]\n",
    "    input_text = example.get(\"input\", \"\")\n",
    "    output_text = example[\"output\"]\n",
    "\n",
    "    if input_text.strip():\n",
    "        prompt = f\"\"\"請仔細閱讀以下文章，理解內容後，學習其中的邏輯，逐步排除選項，並最終選擇最正確的答案。只需要回覆正確的數字選項 (1, 2, 3, 或 4)。\n",
    "        \n",
    "        ### 指令:\n",
    "        {instruction}\n",
    "\n",
    "        ### 內容:\n",
    "        {input_text}\n",
    "\n",
    "        ### 最終答案:\n",
    "        \"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"下面是描述任務的指令。編寫適當完成請求的回應。\n",
    "\n",
    "        ### 指令:\n",
    "        {instruction}\n",
    "\n",
    "        ### 最終答案:\"\"\"\n",
    "\n",
    "    return prompt, output_text\n",
    "\n",
    "def tokenize_fn(example):\n",
    "    prompt, answer = format_example(example)\n",
    "    full_text = prompt + answer\n",
    "\n",
    "    tokenized_prompt = tokenizer(prompt, truncation=False, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    tokenized_answer = tokenizer(answer, truncation=False, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    dynamic_max_length = min(MAX_LENGTH, len(tokenized_prompt[0]) + len(tokenized_answer[0]) + 10)\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        full_text,\n",
    "        max_length=dynamic_max_length,  \n",
    "        truncation=True,\n",
    "        padding=\"max_length\",           # 使用填充\n",
    "    )\n",
    "\n",
    "    prompt_len = len(tokenized_prompt[0])\n",
    "    labels = encoding[\"input_ids\"].copy()\n",
    "    labels[:prompt_len] = [-100] * prompt_len\n",
    "    # print(f\"有效 labels 数量: {sum(1 for label in labels if label != -100)}\")\n",
    "    \n",
    "    return {\"input_ids\": encoding[\"input_ids\"], \"labels\": labels}\n",
    "\n",
    "\n",
    "# --------------- C) 載入 base model (Alpaca) ---------------\n",
    "base_model_name = \"shibing624/chinese-alpaca-plus-7b-hf\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "# 設定 tokenizer 的 pad_token_id\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(\"[PAD]\")\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    load_in_8bit=True,    # 利用 8-bit 量化, 節省顯存\n",
    "    device_map=\"auto\",    # 自動分配 GPU\n",
    ")\n",
    "\n",
    "# --------------- D) 設定 LoRA ---------------\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"], \n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# --------------- E) 準備 Dataset ---------------\n",
    "train_data_list = load_data(\"train.json\")\n",
    "train_dataset = Dataset.from_list(train_data_list)\n",
    "train_dataset = train_dataset.map(tokenize_fn)\n",
    "\n",
    "# 如果有驗證集 (valid_data.json)，可同理做 valid_dataset\n",
    "# valid_data_list = load_data(\"valid_data.json\")\n",
    "# valid_dataset = Dataset.from_list(valid_data_list).map(tokenize_fn)\n",
    "\n",
    "# --------------- F) 設定 TrainingArguments ---------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=1,    \n",
    "    gradient_accumulation_steps=32,     \n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    bf16=True,\n",
    "    logging_steps=20,\n",
    "    save_steps=3000,\n",
    "    save_total_limit=1,\n",
    "    disable_tqdm=False,                 # 顯示tqdm\n",
    "    logging_strategy=\"steps\",           # 每steps都log\n",
    "    report_to=[],                       # 不用wandb\n",
    ")\n",
    "\n",
    "# --------------- G) 建立 Trainer 並微調 ---------------\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True,  \n",
    "    pad_to_multiple_of=8,  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,  \n",
    ")\n",
    "\n",
    "for step, _ in enumerate(trainer.get_train_dataloader()):\n",
    "    if step % 100 == 0:  # 定期清理缓存\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "print(\"LoRA fine-tune is done! The adapter is saved at:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chihhung/.conda/envs/test/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/chihhung/.conda/envs/test/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda116.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/chihhung/.conda/envs/test/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 116\n",
      "CUDA SETUP: Loading binary /home/chihhung/.conda/envs/test/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda116.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chihhung/.conda/envs/test/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/chihhung/.conda/envs/test/lib/libcudart.so.11.0'), PosixPath('/home/chihhung/.conda/envs/test/lib/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "/home/chihhung/.conda/envs/test/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/chihhung/.conda/envs/test/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.74s/it]\n",
      "/home/chihhung/.conda/envs/test/lib/python3.10/site-packages/peft/peft_model.py:556: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  adapters_weights = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID=10023321, Answer=4\n",
      "ID=10076124, Answer=1\n",
      "ID=10292442, Answer=1\n",
      "ID=10450610, Answer=3\n",
      "ID=10466910, Answer=2\n",
      "ID=10498495, Answer=4\n",
      "ID=10598939, Answer=4\n",
      "ID=10657631, Answer=1\n",
      "ID=10697984, Answer=4\n",
      "ID=10755199, Answer=4\n",
      "ID=10893831, Answer=2\n",
      "ID=10899468, Answer=3\n",
      "ID=11029747, Answer=2\n",
      "ID=11115650, Answer=1\n",
      "ID=11171068, Answer=2\n",
      "ID=11264504, Answer=1\n",
      "ID=11300704, Answer=1\n",
      "ID=11321456, Answer=4\n",
      "ID=11348435, Answer=1\n",
      "ID=11368101, Answer=4\n",
      "ID=11423982, Answer=1\n",
      "ID=11516995, Answer=3\n",
      "ID=11556898, Answer=2\n",
      "ID=11693578, Answer=3\n",
      "ID=11753162, Answer=3\n",
      "ID=11813456, Answer=3\n",
      "ID=11838237, Answer=3\n",
      "ID=11891863, Answer=3\n",
      "ID=12099579, Answer=1\n",
      "ID=12102484, Answer=2\n",
      "ID=12150342, Answer=1\n",
      "ID=12246676, Answer=4\n",
      "ID=12445203, Answer=2\n",
      "ID=12698762, Answer=1\n",
      "ID=12884075, Answer=1\n",
      "ID=12926965, Answer=4\n",
      "ID=13007916, Answer=4\n",
      "ID=13112037, Answer=1\n",
      "ID=13154559, Answer=1\n",
      "ID=13258450, Answer=2\n",
      "ID=13355897, Answer=3\n",
      "ID=13609500, Answer=2\n",
      "ID=13610809, Answer=4\n",
      "ID=13691360, Answer=1\n",
      "ID=13763772, Answer=3\n",
      "ID=13766210, Answer=1\n",
      "ID=13984831, Answer=4\n",
      "ID=14239854, Answer=3\n",
      "ID=14280563, Answer=1\n",
      "ID=14369409, Answer=2\n",
      "ID=14396639, Answer=1\n",
      "ID=14492855, Answer=2\n",
      "ID=14571007, Answer=2\n",
      "ID=14709051, Answer=3\n",
      "ID=14814753, Answer=2\n",
      "ID=14908693, Answer=3\n",
      "ID=15117062, Answer=1\n",
      "ID=15168293, Answer=2\n",
      "ID=15192355, Answer=3\n",
      "ID=15227387, Answer=2\n",
      "ID=15398662, Answer=2\n",
      "ID=15912226, Answer=2\n",
      "ID=15951075, Answer=2\n",
      "ID=16193830, Answer=3\n",
      "ID=16204497, Answer=2\n",
      "ID=16362129, Answer=4\n",
      "ID=16407193, Answer=2\n",
      "ID=16457852, Answer=3\n",
      "ID=16518476, Answer=2\n",
      "ID=16546810, Answer=3\n",
      "ID=16549356, Answer=3\n",
      "ID=16703406, Answer=3\n",
      "ID=16898108, Answer=3\n",
      "ID=16909153, Answer=1\n",
      "ID=16910649, Answer=3\n",
      "ID=16983731, Answer=1\n",
      "ID=17019434, Answer=2\n",
      "ID=17329587, Answer=1\n",
      "ID=17471896, Answer=3\n",
      "ID=17724480, Answer=1\n",
      "ID=17873549, Answer=2\n",
      "ID=18128262, Answer=1\n",
      "ID=18178799, Answer=3\n",
      "ID=18257409, Answer=2\n",
      "ID=18397693, Answer=1\n",
      "ID=18492824, Answer=1\n",
      "ID=18515874, Answer=3\n",
      "ID=18741469, Answer=2\n",
      "ID=18779447, Answer=2\n",
      "ID=18989913, Answer=1\n",
      "ID=19038866, Answer=3\n",
      "ID=19212462, Answer=2\n",
      "ID=19220703, Answer=3\n",
      "ID=19277838, Answer=1\n",
      "ID=19303177, Answer=2\n",
      "ID=19445297, Answer=3\n",
      "ID=19463064, Answer=3\n",
      "ID=19576366, Answer=4\n",
      "ID=19584616, Answer=2\n",
      "ID=19662077, Answer=3\n",
      "ID=19675519, Answer=3\n",
      "ID=19714653, Answer=2\n",
      "ID=19720602, Answer=3\n",
      "ID=19827337, Answer=2\n",
      "ID=19953743, Answer=4\n",
      "ID=19954659, Answer=3\n",
      "ID=20073793, Answer=4\n",
      "ID=20094174, Answer=3\n",
      "ID=20142679, Answer=4\n",
      "ID=20212100, Answer=1\n",
      "ID=20336490, Answer=2\n",
      "ID=20513965, Answer=3\n",
      "ID=20583494, Answer=3\n",
      "ID=20593833, Answer=2\n",
      "ID=20625301, Answer=1\n",
      "ID=20634540, Answer=4\n",
      "ID=20720072, Answer=3\n",
      "ID=20736627, Answer=1\n",
      "ID=20929290, Answer=1\n",
      "ID=21016444, Answer=1\n",
      "ID=21106935, Answer=3\n",
      "ID=21189878, Answer=4\n",
      "ID=21226453, Answer=2\n",
      "ID=21336728, Answer=4\n",
      "ID=21351331, Answer=4\n",
      "ID=21369991, Answer=4\n",
      "ID=21561344, Answer=3\n",
      "ID=21577123, Answer=1\n",
      "ID=21743020, Answer=3\n",
      "ID=21763747, Answer=4\n",
      "ID=21778173, Answer=2\n",
      "ID=21820433, Answer=4\n",
      "ID=21931231, Answer=4\n",
      "ID=22016589, Answer=3\n",
      "ID=22100377, Answer=2\n",
      "ID=22101890, Answer=3\n",
      "ID=22229083, Answer=2\n",
      "ID=22367603, Answer=2\n",
      "ID=22386247, Answer=1\n",
      "ID=22507162, Answer=1\n",
      "ID=22758996, Answer=1\n",
      "ID=22988063, Answer=1\n",
      "ID=23009422, Answer=2\n",
      "ID=23064985, Answer=3\n",
      "ID=23094030, Answer=3\n",
      "ID=23120095, Answer=2\n",
      "ID=23185450, Answer=3\n",
      "ID=23333701, Answer=2\n",
      "ID=23352935, Answer=4\n",
      "ID=23378299, Answer=4\n",
      "ID=23522594, Answer=4\n",
      "ID=23608299, Answer=4\n",
      "ID=23817944, Answer=2\n",
      "ID=23930613, Answer=4\n",
      "ID=24143628, Answer=2\n",
      "ID=24263046, Answer=3\n",
      "ID=24355799, Answer=2\n",
      "ID=24365031, Answer=4\n",
      "ID=24435016, Answer=1\n",
      "ID=24449680, Answer=4\n",
      "ID=24542374, Answer=2\n",
      "ID=24610726, Answer=3\n",
      "ID=24649708, Answer=4\n",
      "ID=24676882, Answer=2\n",
      "ID=24884065, Answer=4\n",
      "ID=24910497, Answer=3\n",
      "ID=24972835, Answer=2\n",
      "ID=25019784, Answer=1\n",
      "ID=25082737, Answer=2\n",
      "ID=25199776, Answer=1\n",
      "ID=25264183, Answer=1\n",
      "ID=25344713, Answer=2\n",
      "ID=25498596, Answer=3\n",
      "ID=25543707, Answer=2\n",
      "ID=25556764, Answer=4\n",
      "ID=25571050, Answer=2\n",
      "ID=25641937, Answer=2\n",
      "ID=25697929, Answer=2\n",
      "ID=25748090, Answer=2\n",
      "ID=25771114, Answer=2\n",
      "ID=25780278, Answer=2\n",
      "ID=25792979, Answer=2\n",
      "ID=25820129, Answer=3\n",
      "ID=25836968, Answer=3\n",
      "ID=25892380, Answer=1\n",
      "ID=26027353, Answer=2\n",
      "ID=26157663, Answer=3\n",
      "ID=26186497, Answer=4\n",
      "ID=26210726, Answer=2\n",
      "ID=26227064, Answer=3\n",
      "ID=26330504, Answer=2\n",
      "ID=26381972, Answer=4\n",
      "ID=26460032, Answer=1\n",
      "ID=26533393, Answer=2\n",
      "ID=26535956, Answer=1\n",
      "ID=26607564, Answer=4\n",
      "ID=26647314, Answer=4\n",
      "ID=26656486, Answer=2\n",
      "ID=26724971, Answer=3\n",
      "ID=26921201, Answer=4\n",
      "ID=26936231, Answer=3\n",
      "ID=26968505, Answer=2\n",
      "ID=27322080, Answer=3\n",
      "ID=27332335, Answer=4\n",
      "ID=27363514, Answer=3\n",
      "ID=27618457, Answer=1\n",
      "ID=27630450, Answer=1\n",
      "ID=27831894, Answer=3\n",
      "ID=27947154, Answer=3\n",
      "ID=27952572, Answer=3\n",
      "ID=27969464, Answer=3\n",
      "ID=28015653, Answer=4\n",
      "ID=28092570, Answer=1\n",
      "ID=28220506, Answer=4\n",
      "ID=28279100, Answer=2\n",
      "ID=28443714, Answer=4\n",
      "ID=28516385, Answer=2\n",
      "ID=28695603, Answer=2\n",
      "ID=28701210, Answer=4\n",
      "ID=28725148, Answer=3\n",
      "ID=28802066, Answer=3\n",
      "ID=29074746, Answer=2\n",
      "ID=29135757, Answer=3\n",
      "ID=29197407, Answer=3\n",
      "ID=29220937, Answer=1\n",
      "ID=29246936, Answer=2\n",
      "ID=29310798, Answer=1\n",
      "ID=29349634, Answer=3\n",
      "ID=29634427, Answer=4\n",
      "ID=29810805, Answer=3\n",
      "ID=29938730, Answer=3\n",
      "ID=30090975, Answer=1\n",
      "ID=30103282, Answer=4\n",
      "ID=30103343, Answer=2\n",
      "ID=30301090, Answer=3\n",
      "ID=30351914, Answer=2\n",
      "ID=30446630, Answer=2\n",
      "ID=30538256, Answer=2\n",
      "ID=30614498, Answer=3\n",
      "ID=30717875, Answer=3\n",
      "ID=30888639, Answer=4\n",
      "ID=30916139, Answer=1\n",
      "ID=30920549, Answer=2\n",
      "ID=30927330, Answer=3\n",
      "ID=31052796, Answer=3\n",
      "ID=31082653, Answer=3\n",
      "ID=31204497, Answer=2\n",
      "ID=31297308, Answer=3\n",
      "ID=31388061, Answer=1\n",
      "ID=31418038, Answer=3\n",
      "ID=31491549, Answer=2\n",
      "ID=31529728, Answer=4\n",
      "ID=31656758, Answer=3\n",
      "ID=31929624, Answer=2\n",
      "ID=32010797, Answer=2\n",
      "ID=32065696, Answer=1\n",
      "ID=32113189, Answer=2\n",
      "ID=32354842, Answer=4\n",
      "ID=32373063, Answer=4\n",
      "ID=32512700, Answer=4\n",
      "ID=32528495, Answer=3\n",
      "ID=32538170, Answer=3\n",
      "ID=32745936, Answer=4\n",
      "ID=32815343, Answer=1\n",
      "ID=32827530, Answer=2\n",
      "ID=32877429, Answer=2\n",
      "ID=32923350, Answer=4\n",
      "ID=32999142, Answer=3\n",
      "ID=33193908, Answer=3\n",
      "ID=33216442, Answer=1\n",
      "ID=33339940, Answer=4\n",
      "ID=33356590, Answer=4\n",
      "ID=33438579, Answer=4\n",
      "ID=33481747, Answer=1\n",
      "ID=33734254, Answer=4\n",
      "ID=33792933, Answer=3\n",
      "ID=33797297, Answer=1\n",
      "ID=33989028, Answer=3\n",
      "ID=34100541, Answer=3\n",
      "ID=34165479, Answer=4\n",
      "ID=34314302, Answer=3\n",
      "ID=34413826, Answer=1\n",
      "ID=34483223, Answer=2\n",
      "ID=34531294, Answer=1\n",
      "ID=34596882, Answer=1\n",
      "ID=34786269, Answer=2\n",
      "ID=34833527, Answer=3\n",
      "ID=34979667, Answer=2\n",
      "ID=34999260, Answer=1\n",
      "ID=35086193, Answer=1\n",
      "ID=35086611, Answer=2\n",
      "ID=35148524, Answer=4\n",
      "ID=35190340, Answer=2\n",
      "ID=35377022, Answer=2\n",
      "ID=35388601, Answer=2\n",
      "ID=35496107, Answer=3\n",
      "ID=35626112, Answer=3\n",
      "ID=35660762, Answer=2\n",
      "ID=35683046, Answer=2\n",
      "ID=35686634, Answer=2\n",
      "ID=35690404, Answer=4\n",
      "ID=35726050, Answer=2\n",
      "ID=35889309, Answer=2\n",
      "ID=35996402, Answer=4\n",
      "ID=36128561, Answer=3\n",
      "ID=36151996, Answer=1\n",
      "ID=36464231, Answer=3\n",
      "ID=36466099, Answer=3\n",
      "ID=36777664, Answer=2\n",
      "ID=36780224, Answer=2\n",
      "ID=36921231, Answer=3\n",
      "ID=36927037, Answer=2\n",
      "ID=36979416, Answer=2\n",
      "ID=37009957, Answer=3\n",
      "ID=37037764, Answer=1\n",
      "ID=37393415, Answer=1\n",
      "ID=37716553, Answer=4\n",
      "ID=37872188, Answer=1\n",
      "ID=37946620, Answer=1\n",
      "ID=38148049, Answer=2\n",
      "ID=38162949, Answer=1\n",
      "ID=38316553, Answer=2\n",
      "ID=38576994, Answer=4\n",
      "ID=38722560, Answer=3\n",
      "ID=38794952, Answer=1\n",
      "ID=38876311, Answer=2\n",
      "ID=39037060, Answer=4\n",
      "ID=39205257, Answer=4\n",
      "ID=39250564, Answer=4\n",
      "ID=39342484, Answer=3\n",
      "ID=39370749, Answer=4\n",
      "ID=39457290, Answer=3\n",
      "ID=39469100, Answer=2\n",
      "ID=39472570, Answer=3\n",
      "ID=39615550, Answer=3\n",
      "ID=39623148, Answer=3\n",
      "ID=39740294, Answer=1\n",
      "ID=39860584, Answer=3\n",
      "ID=39915817, Answer=3\n",
      "ID=40267484, Answer=2\n",
      "ID=40342498, Answer=2\n",
      "ID=40485081, Answer=1\n",
      "ID=40607676, Answer=3\n",
      "ID=40678959, Answer=1\n",
      "ID=40704733, Answer=3\n",
      "ID=40817799, Answer=2\n",
      "ID=40852250, Answer=3\n",
      "ID=40893184, Answer=1\n",
      "ID=41054040, Answer=4\n",
      "ID=41260821, Answer=4\n",
      "ID=41294659, Answer=2\n",
      "ID=41634618, Answer=1\n",
      "ID=41646437, Answer=1\n",
      "ID=41674658, Answer=4\n",
      "ID=41896433, Answer=4\n",
      "ID=42024282, Answer=2\n",
      "ID=42037518, Answer=4\n",
      "ID=42044798, Answer=1\n",
      "ID=42270254, Answer=2\n",
      "ID=42276779, Answer=1\n",
      "ID=42310855, Answer=4\n",
      "ID=42356310, Answer=2\n",
      "ID=42423693, Answer=3\n",
      "ID=42464984, Answer=2\n",
      "ID=42503762, Answer=4\n",
      "ID=42554751, Answer=2\n",
      "ID=42883747, Answer=3\n",
      "ID=42913341, Answer=4\n",
      "ID=42992438, Answer=1\n",
      "ID=43031177, Answer=2\n",
      "ID=43154080, Answer=4\n",
      "ID=43241506, Answer=3\n",
      "ID=43282777, Answer=4\n",
      "ID=43462849, Answer=1\n",
      "ID=43596953, Answer=1\n",
      "ID=43681892, Answer=1\n",
      "ID=43748728, Answer=2\n",
      "ID=43764994, Answer=3\n",
      "ID=43809667, Answer=3\n",
      "ID=43936611, Answer=2\n",
      "ID=44034184, Answer=4\n",
      "ID=44305696, Answer=3\n",
      "ID=44384618, Answer=3\n",
      "ID=44444743, Answer=3\n",
      "ID=44494522, Answer=4\n",
      "ID=44528461, Answer=3\n",
      "ID=44758733, Answer=4\n",
      "ID=44916808, Answer=3\n",
      "ID=44989428, Answer=1\n",
      "ID=45033275, Answer=4\n",
      "ID=45212997, Answer=3\n",
      "ID=45277639, Answer=3\n",
      "ID=45377503, Answer=3\n",
      "ID=45424161, Answer=4\n",
      "ID=45492456, Answer=3\n",
      "ID=45573277, Answer=1\n",
      "ID=45707007, Answer=4\n",
      "ID=45721011, Answer=4\n",
      "ID=45858186, Answer=4\n",
      "ID=45887033, Answer=2\n",
      "ID=46279778, Answer=3\n",
      "ID=46478391, Answer=3\n",
      "ID=46657991, Answer=2\n",
      "ID=46790338, Answer=4\n",
      "ID=47025738, Answer=3\n",
      "ID=47191375, Answer=1\n",
      "ID=47280828, Answer=2\n",
      "ID=47360608, Answer=4\n",
      "ID=47372380, Answer=3\n",
      "ID=47891041, Answer=3\n",
      "ID=48059548, Answer=4\n",
      "ID=48124050, Answer=1\n",
      "ID=48182413, Answer=3\n",
      "ID=48213959, Answer=3\n",
      "ID=48309802, Answer=2\n",
      "ID=48371253, Answer=1\n",
      "ID=48445433, Answer=4\n",
      "ID=48508684, Answer=2\n",
      "ID=48641187, Answer=1\n",
      "ID=48761892, Answer=2\n",
      "ID=48899741, Answer=2\n",
      "ID=48992758, Answer=1\n",
      "ID=49014843, Answer=3\n",
      "ID=49097615, Answer=3\n",
      "ID=49101607, Answer=4\n",
      "ID=49199740, Answer=1\n",
      "ID=49301192, Answer=4\n",
      "ID=49345576, Answer=4\n",
      "ID=49494468, Answer=3\n",
      "ID=49672872, Answer=2\n",
      "ID=49909534, Answer=2\n",
      "ID=49927530, Answer=4\n",
      "ID=49971434, Answer=2\n",
      "ID=50027320, Answer=3\n",
      "ID=50041578, Answer=4\n",
      "ID=50056043, Answer=1\n",
      "ID=50245418, Answer=3\n",
      "ID=50250811, Answer=2\n",
      "ID=50497638, Answer=4\n",
      "ID=50506871, Answer=3\n",
      "ID=50547976, Answer=3\n",
      "ID=50612944, Answer=3\n",
      "ID=50687196, Answer=2\n",
      "ID=50768900, Answer=1\n",
      "ID=50966204, Answer=1\n",
      "ID=50992179, Answer=1\n",
      "ID=51000853, Answer=4\n",
      "ID=51037962, Answer=2\n",
      "ID=51177478, Answer=3\n",
      "ID=51177767, Answer=2\n",
      "ID=51468230, Answer=3\n",
      "ID=51515317, Answer=4\n",
      "ID=51593301, Answer=2\n",
      "ID=51641638, Answer=2\n",
      "ID=51706669, Answer=4\n",
      "ID=51991177, Answer=2\n",
      "ID=52042156, Answer=4\n",
      "ID=52095705, Answer=2\n",
      "ID=52310324, Answer=2\n",
      "ID=52367944, Answer=2\n",
      "ID=52496524, Answer=3\n",
      "ID=52508855, Answer=2\n",
      "ID=52548519, Answer=3\n",
      "ID=52625207, Answer=2\n",
      "ID=52626596, Answer=3\n",
      "ID=52646281, Answer=3\n",
      "ID=52738229, Answer=4\n",
      "ID=52951154, Answer=3\n",
      "ID=53167269, Answer=3\n",
      "ID=53206407, Answer=1\n",
      "ID=53307108, Answer=1\n",
      "ID=53389303, Answer=2\n",
      "ID=53670420, Answer=2\n",
      "ID=53749565, Answer=1\n",
      "ID=53881027, Answer=4\n",
      "ID=53985915, Answer=3\n",
      "ID=54010869, Answer=3\n",
      "ID=54181581, Answer=2\n",
      "ID=54248885, Answer=3\n",
      "ID=54382171, Answer=3\n",
      "ID=54562016, Answer=1\n",
      "ID=54563893, Answer=1\n",
      "ID=54567832, Answer=3\n",
      "ID=54579633, Answer=2\n",
      "ID=54703635, Answer=2\n",
      "ID=55013257, Answer=3\n",
      "ID=55022132, Answer=2\n",
      "ID=55031777, Answer=1\n",
      "ID=55113922, Answer=4\n",
      "ID=55168507, Answer=2\n",
      "ID=55185532, Answer=3\n",
      "ID=55295938, Answer=1\n",
      "ID=55384860, Answer=3\n",
      "ID=55405606, Answer=1\n",
      "ID=55543404, Answer=1\n",
      "ID=55633512, Answer=3\n",
      "ID=55778234, Answer=1\n",
      "ID=55834141, Answer=1\n",
      "ID=55881902, Answer=3\n",
      "ID=55904212, Answer=2\n",
      "ID=55969081, Answer=4\n",
      "ID=56073710, Answer=3\n",
      "ID=56139505, Answer=4\n",
      "ID=56167998, Answer=1\n",
      "ID=56412334, Answer=3\n",
      "ID=56413209, Answer=3\n",
      "ID=56712590, Answer=2\n",
      "ID=56789552, Answer=1\n",
      "ID=56857979, Answer=2\n",
      "ID=56933634, Answer=4\n",
      "ID=56950104, Answer=3\n",
      "ID=56995889, Answer=4\n",
      "ID=57025942, Answer=3\n",
      "ID=57031941, Answer=2\n",
      "ID=57156762, Answer=4\n",
      "ID=57221803, Answer=2\n",
      "ID=57443301, Answer=2\n",
      "ID=57481416, Answer=2\n",
      "ID=57948540, Answer=3\n",
      "ID=58013283, Answer=1\n",
      "ID=58023829, Answer=2\n",
      "ID=58049946, Answer=1\n",
      "ID=58147431, Answer=1\n",
      "ID=58172260, Answer=1\n",
      "ID=58254705, Answer=4\n",
      "ID=58317090, Answer=2\n",
      "ID=58462760, Answer=4\n",
      "ID=58463253, Answer=3\n",
      "ID=58475200, Answer=3\n",
      "ID=58546022, Answer=3\n",
      "ID=58555292, Answer=2\n",
      "ID=58598675, Answer=3\n",
      "ID=58678601, Answer=3\n",
      "ID=58818792, Answer=4\n",
      "ID=58832479, Answer=4\n",
      "ID=58990864, Answer=1\n",
      "ID=59032166, Answer=1\n",
      "ID=59042732, Answer=2\n",
      "ID=59084478, Answer=4\n",
      "ID=59152721, Answer=2\n",
      "ID=59171652, Answer=1\n",
      "ID=59283896, Answer=3\n",
      "ID=59685946, Answer=2\n",
      "ID=59801676, Answer=3\n",
      "ID=59813140, Answer=4\n",
      "ID=59829685, Answer=1\n",
      "ID=59876920, Answer=3\n",
      "ID=60006119, Answer=3\n",
      "ID=60041433, Answer=4\n",
      "ID=60081463, Answer=2\n",
      "ID=60139445, Answer=2\n",
      "ID=60158284, Answer=3\n",
      "ID=60224213, Answer=3\n",
      "ID=60360747, Answer=1\n",
      "ID=60572316, Answer=3\n",
      "ID=60604361, Answer=2\n",
      "ID=60766632, Answer=4\n",
      "ID=61015678, Answer=2\n",
      "ID=61066421, Answer=3\n",
      "ID=61227364, Answer=4\n",
      "ID=61258191, Answer=3\n",
      "ID=61282049, Answer=2\n",
      "ID=61337359, Answer=3\n",
      "ID=61394815, Answer=3\n",
      "ID=61746117, Answer=4\n",
      "ID=61868774, Answer=2\n",
      "ID=61927316, Answer=3\n",
      "ID=62018518, Answer=3\n",
      "ID=62258809, Answer=4\n",
      "ID=62410737, Answer=4\n",
      "ID=62421989, Answer=3\n",
      "ID=62525579, Answer=3\n",
      "ID=62566935, Answer=3\n",
      "ID=62568620, Answer=1\n",
      "ID=62628400, Answer=3\n",
      "ID=62661238, Answer=1\n",
      "ID=62932598, Answer=1\n",
      "ID=63077572, Answer=2\n",
      "ID=63127771, Answer=3\n",
      "ID=63157537, Answer=4\n",
      "ID=63257384, Answer=2\n",
      "ID=63422381, Answer=3\n",
      "ID=63575501, Answer=3\n",
      "ID=63620958, Answer=4\n",
      "ID=63725684, Answer=1\n",
      "ID=63751215, Answer=2\n",
      "ID=64110599, Answer=1\n",
      "ID=64115714, Answer=1\n",
      "ID=64229392, Answer=2\n",
      "ID=64293316, Answer=4\n",
      "ID=64306025, Answer=1\n",
      "ID=64377473, Answer=3\n",
      "ID=64437287, Answer=4\n",
      "ID=64530635, Answer=2\n",
      "ID=64715270, Answer=3\n",
      "ID=64748858, Answer=3\n",
      "ID=65114154, Answer=1\n",
      "ID=65145549, Answer=3\n",
      "ID=65411632, Answer=2\n",
      "ID=65453053, Answer=1\n",
      "ID=65506693, Answer=3\n",
      "ID=65509215, Answer=1\n",
      "ID=65646532, Answer=2\n",
      "ID=65704876, Answer=2\n",
      "ID=65780965, Answer=1\n",
      "ID=65805259, Answer=4\n",
      "ID=65842325, Answer=1\n",
      "ID=65861936, Answer=4\n",
      "ID=65865253, Answer=4\n",
      "ID=65953217, Answer=3\n",
      "ID=66060112, Answer=1\n",
      "ID=66117519, Answer=1\n",
      "ID=66148268, Answer=1\n",
      "ID=66356435, Answer=3\n",
      "ID=66405350, Answer=4\n",
      "ID=66453737, Answer=1\n",
      "ID=66480707, Answer=2\n",
      "ID=66503529, Answer=3\n",
      "ID=66595852, Answer=2\n",
      "ID=66696281, Answer=3\n",
      "ID=66799160, Answer=2\n",
      "ID=66976830, Answer=2\n",
      "ID=67106903, Answer=3\n",
      "ID=67163001, Answer=3\n",
      "ID=67235198, Answer=3\n",
      "ID=67289981, Answer=4\n",
      "ID=67408250, Answer=1\n",
      "ID=67480852, Answer=1\n",
      "ID=67513152, Answer=1\n",
      "ID=67683385, Answer=2\n",
      "ID=67688621, Answer=1\n",
      "ID=67778544, Answer=1\n",
      "ID=67825032, Answer=2\n",
      "ID=67832199, Answer=2\n",
      "ID=67927901, Answer=3\n",
      "ID=67944966, Answer=1\n",
      "ID=68078340, Answer=3\n",
      "ID=68082849, Answer=2\n",
      "ID=68099165, Answer=3\n",
      "ID=68099673, Answer=4\n",
      "ID=68133679, Answer=3\n",
      "ID=68154151, Answer=1\n",
      "ID=68216603, Answer=4\n",
      "ID=68244553, Answer=2\n",
      "ID=68274304, Answer=2\n",
      "ID=68478450, Answer=3\n",
      "ID=68611024, Answer=1\n",
      "ID=68645504, Answer=3\n",
      "ID=68667103, Answer=3\n",
      "ID=68735218, Answer=1\n",
      "ID=68751149, Answer=1\n",
      "ID=68754837, Answer=4\n",
      "ID=69105652, Answer=3\n",
      "ID=69487234, Answer=2\n",
      "ID=69653431, Answer=3\n",
      "ID=69816409, Answer=2\n",
      "ID=69818083, Answer=3\n",
      "ID=70135990, Answer=2\n",
      "ID=70145987, Answer=4\n",
      "ID=70159892, Answer=2\n",
      "ID=70201233, Answer=4\n",
      "ID=70288331, Answer=3\n",
      "ID=70553884, Answer=3\n",
      "ID=70652366, Answer=2\n",
      "ID=70707750, Answer=4\n",
      "ID=70724683, Answer=3\n",
      "ID=70805594, Answer=3\n",
      "ID=70899055, Answer=4\n",
      "ID=70936275, Answer=1\n",
      "ID=70949010, Answer=2\n",
      "ID=70973659, Answer=2\n",
      "ID=70977664, Answer=2\n",
      "ID=71283614, Answer=3\n",
      "ID=71305448, Answer=1\n",
      "ID=71330218, Answer=4\n",
      "ID=71332468, Answer=2\n",
      "ID=71366193, Answer=2\n",
      "ID=71383278, Answer=3\n",
      "ID=71667045, Answer=4\n",
      "ID=71688526, Answer=3\n",
      "ID=71943986, Answer=1\n",
      "ID=72065904, Answer=3\n",
      "ID=72098807, Answer=2\n",
      "ID=72193999, Answer=2\n",
      "ID=72330024, Answer=3\n",
      "ID=72458278, Answer=2\n",
      "ID=72600221, Answer=2\n",
      "ID=72648975, Answer=2\n",
      "ID=73107585, Answer=3\n",
      "ID=73229523, Answer=4\n",
      "ID=73290874, Answer=2\n",
      "ID=73345500, Answer=3\n",
      "ID=73517783, Answer=2\n",
      "ID=73565277, Answer=4\n",
      "ID=73603262, Answer=2\n",
      "ID=73709065, Answer=1\n",
      "ID=73860597, Answer=1\n",
      "ID=73943128, Answer=3\n",
      "ID=74035476, Answer=4\n",
      "ID=74093956, Answer=1\n",
      "ID=74196140, Answer=3\n",
      "ID=74242894, Answer=3\n",
      "ID=74272614, Answer=4\n",
      "ID=74410650, Answer=1\n",
      "ID=74473886, Answer=3\n",
      "ID=74518209, Answer=2\n",
      "ID=74597028, Answer=2\n",
      "ID=74651804, Answer=3\n",
      "ID=74686588, Answer=4\n",
      "ID=74696366, Answer=3\n",
      "ID=74733153, Answer=2\n",
      "ID=74900896, Answer=4\n",
      "ID=74905625, Answer=4\n",
      "ID=74959346, Answer=4\n",
      "ID=75059061, Answer=3\n",
      "ID=75059555, Answer=2\n",
      "ID=75078606, Answer=2\n",
      "ID=75131081, Answer=2\n",
      "ID=75305241, Answer=4\n",
      "ID=75464392, Answer=1\n",
      "ID=75692356, Answer=3\n",
      "ID=75787193, Answer=2\n",
      "ID=75873067, Answer=3\n",
      "ID=76046406, Answer=1\n",
      "ID=76106989, Answer=4\n",
      "ID=76150336, Answer=1\n",
      "ID=76165769, Answer=3\n",
      "ID=76171840, Answer=3\n",
      "ID=76256596, Answer=1\n",
      "ID=76307536, Answer=2\n",
      "ID=76313317, Answer=3\n",
      "ID=76353307, Answer=3\n",
      "ID=76365620, Answer=4\n",
      "ID=76460663, Answer=3\n",
      "ID=76587897, Answer=3\n",
      "ID=76609139, Answer=2\n",
      "ID=76716323, Answer=1\n",
      "ID=76802508, Answer=2\n",
      "ID=76816634, Answer=1\n",
      "ID=76830921, Answer=1\n",
      "ID=76928466, Answer=3\n",
      "ID=76941799, Answer=4\n",
      "ID=77046849, Answer=3\n",
      "ID=77055680, Answer=3\n",
      "ID=77191908, Answer=2\n",
      "ID=77223130, Answer=4\n",
      "ID=77351033, Answer=2\n",
      "ID=77385014, Answer=4\n",
      "ID=77489893, Answer=1\n",
      "ID=77542276, Answer=3\n",
      "ID=77568643, Answer=4\n",
      "ID=77579186, Answer=3\n",
      "ID=77615090, Answer=3\n",
      "ID=77625307, Answer=3\n",
      "ID=77656181, Answer=3\n",
      "ID=77778761, Answer=1\n",
      "ID=77922941, Answer=1\n",
      "ID=78070257, Answer=1\n",
      "ID=78292622, Answer=4\n",
      "ID=78371095, Answer=4\n",
      "ID=78418870, Answer=1\n",
      "ID=78424571, Answer=1\n",
      "ID=78455034, Answer=4\n",
      "ID=78554132, Answer=3\n",
      "ID=78704818, Answer=3\n",
      "ID=78812539, Answer=3\n",
      "ID=78859312, Answer=1\n",
      "ID=78863985, Answer=2\n",
      "ID=79128204, Answer=4\n",
      "ID=79445573, Answer=4\n",
      "ID=79475961, Answer=2\n",
      "ID=79481164, Answer=2\n",
      "ID=79484337, Answer=1\n",
      "ID=79521846, Answer=4\n",
      "ID=79626238, Answer=3\n",
      "ID=79838033, Answer=4\n",
      "ID=79862714, Answer=2\n",
      "ID=79925355, Answer=3\n",
      "ID=80089041, Answer=2\n",
      "ID=80147902, Answer=3\n",
      "ID=80292130, Answer=3\n",
      "ID=80375966, Answer=2\n",
      "ID=80413498, Answer=2\n",
      "ID=80526466, Answer=1\n",
      "ID=80796404, Answer=4\n",
      "ID=80912341, Answer=2\n",
      "ID=81309761, Answer=4\n",
      "ID=81365939, Answer=3\n",
      "ID=81393484, Answer=1\n",
      "ID=81431090, Answer=4\n",
      "ID=81470530, Answer=2\n",
      "ID=81475034, Answer=2\n",
      "ID=81523252, Answer=4\n",
      "ID=81529488, Answer=4\n",
      "ID=81540226, Answer=1\n",
      "ID=81550727, Answer=4\n",
      "ID=81644700, Answer=3\n",
      "ID=81658464, Answer=3\n",
      "ID=81664693, Answer=4\n",
      "ID=81819221, Answer=2\n",
      "ID=81886619, Answer=3\n",
      "ID=81927587, Answer=1\n",
      "ID=81936940, Answer=4\n",
      "ID=82112909, Answer=1\n",
      "ID=82158851, Answer=4\n",
      "ID=82331983, Answer=4\n",
      "ID=82352006, Answer=3\n",
      "ID=82411272, Answer=2\n",
      "ID=82580870, Answer=3\n",
      "ID=82613409, Answer=4\n",
      "ID=82704835, Answer=4\n",
      "ID=82824301, Answer=3\n",
      "ID=82881242, Answer=3\n",
      "ID=82904957, Answer=3\n",
      "ID=82962895, Answer=4\n",
      "ID=83039782, Answer=1\n",
      "ID=83265943, Answer=3\n",
      "ID=83271023, Answer=1\n",
      "ID=83511300, Answer=3\n",
      "ID=83521315, Answer=4\n",
      "ID=83611299, Answer=2\n",
      "ID=83658769, Answer=3\n",
      "ID=83728881, Answer=3\n",
      "ID=83782100, Answer=2\n",
      "ID=83940944, Answer=3\n",
      "ID=84031466, Answer=2\n",
      "ID=84033787, Answer=3\n",
      "ID=84094119, Answer=3\n",
      "ID=84111897, Answer=4\n",
      "ID=84156694, Answer=3\n",
      "ID=84187169, Answer=3\n",
      "ID=84188564, Answer=3\n",
      "ID=84282018, Answer=3\n",
      "ID=84306779, Answer=2\n",
      "ID=84451702, Answer=1\n",
      "ID=84473599, Answer=3\n",
      "ID=84743378, Answer=4\n",
      "ID=84755024, Answer=3\n",
      "ID=84796226, Answer=2\n",
      "ID=84950682, Answer=4\n",
      "ID=84968926, Answer=3\n",
      "ID=85023084, Answer=3\n",
      "ID=85257776, Answer=2\n",
      "ID=85288088, Answer=3\n",
      "ID=85399160, Answer=1\n",
      "ID=85499220, Answer=3\n",
      "ID=85514149, Answer=4\n",
      "ID=85552240, Answer=2\n",
      "ID=85568783, Answer=3\n",
      "ID=85622370, Answer=1\n",
      "ID=85628436, Answer=1\n",
      "ID=85936937, Answer=1\n",
      "ID=86045512, Answer=3\n",
      "ID=86061857, Answer=1\n",
      "ID=86144637, Answer=3\n",
      "ID=86191535, Answer=4\n",
      "ID=86267405, Answer=4\n",
      "ID=86275141, Answer=1\n",
      "ID=86282620, Answer=4\n",
      "ID=86704920, Answer=2\n",
      "ID=86732024, Answer=2\n",
      "ID=86795766, Answer=4\n",
      "ID=86802959, Answer=3\n",
      "ID=86895680, Answer=1\n",
      "ID=86940522, Answer=1\n",
      "ID=86965358, Answer=1\n",
      "ID=87104232, Answer=3\n",
      "ID=87202322, Answer=2\n",
      "ID=87371423, Answer=4\n",
      "ID=87557229, Answer=3\n",
      "ID=87612483, Answer=3\n",
      "ID=87710423, Answer=1\n",
      "ID=87860223, Answer=4\n",
      "ID=87953343, Answer=1\n",
      "ID=88138234, Answer=4\n",
      "ID=88308145, Answer=4\n",
      "ID=88593051, Answer=3\n",
      "ID=88736969, Answer=1\n",
      "ID=88801705, Answer=3\n",
      "ID=89059540, Answer=4\n",
      "ID=89081452, Answer=3\n",
      "ID=89085362, Answer=3\n",
      "ID=89162865, Answer=2\n",
      "ID=89347218, Answer=1\n",
      "ID=89444676, Answer=4\n",
      "ID=89485108, Answer=3\n",
      "ID=89548280, Answer=3\n",
      "ID=89562203, Answer=1\n",
      "ID=89562802, Answer=3\n",
      "ID=89655213, Answer=4\n",
      "ID=89661254, Answer=1\n",
      "ID=89691137, Answer=3\n",
      "ID=89719394, Answer=1\n",
      "ID=89867153, Answer=2\n",
      "ID=89922717, Answer=4\n",
      "ID=89967925, Answer=3\n",
      "ID=89987139, Answer=4\n",
      "ID=90079815, Answer=3\n",
      "ID=90182926, Answer=3\n",
      "ID=90207524, Answer=3\n",
      "ID=90355334, Answer=4\n",
      "ID=90417297, Answer=2\n",
      "ID=90447911, Answer=3\n",
      "ID=90475835, Answer=1\n",
      "ID=90521769, Answer=2\n",
      "ID=90580976, Answer=2\n",
      "ID=90677007, Answer=1\n",
      "ID=90683541, Answer=3\n",
      "ID=90750044, Answer=4\n",
      "ID=90789704, Answer=3\n",
      "ID=90818217, Answer=1\n",
      "ID=90870753, Answer=4\n",
      "ID=91019889, Answer=4\n",
      "ID=91036685, Answer=3\n",
      "ID=91194289, Answer=2\n",
      "ID=91401452, Answer=3\n",
      "ID=91597373, Answer=2\n",
      "ID=91764749, Answer=3\n",
      "ID=91785292, Answer=3\n",
      "ID=91957842, Answer=4\n",
      "ID=92100484, Answer=4\n",
      "ID=92115100, Answer=2\n",
      "ID=92195557, Answer=4\n",
      "ID=92269580, Answer=4\n",
      "ID=92304979, Answer=1\n",
      "ID=92366164, Answer=4\n",
      "ID=92369351, Answer=2\n",
      "ID=92537096, Answer=2\n",
      "ID=92569574, Answer=2\n",
      "ID=92597137, Answer=4\n",
      "ID=92632640, Answer=2\n",
      "ID=92892478, Answer=1\n",
      "ID=92931682, Answer=1\n",
      "ID=93007242, Answer=1\n",
      "ID=93091289, Answer=2\n",
      "ID=93253888, Answer=4\n",
      "ID=93264710, Answer=1\n",
      "ID=93432075, Answer=1\n",
      "ID=93439336, Answer=3\n",
      "ID=93469217, Answer=3\n",
      "ID=93666962, Answer=2\n",
      "ID=93787020, Answer=2\n",
      "ID=93832900, Answer=4\n",
      "ID=93892625, Answer=3\n",
      "ID=93945414, Answer=2\n",
      "ID=93986394, Answer=1\n",
      "ID=94045014, Answer=2\n",
      "ID=94489790, Answer=2\n",
      "ID=94796582, Answer=1\n",
      "ID=94911851, Answer=4\n",
      "ID=94964351, Answer=3\n",
      "ID=95016442, Answer=1\n",
      "ID=95271275, Answer=3\n",
      "ID=95444847, Answer=2\n",
      "ID=95541373, Answer=1\n",
      "ID=95546236, Answer=2\n",
      "ID=95891098, Answer=3\n",
      "ID=95968879, Answer=2\n",
      "ID=96248568, Answer=4\n",
      "ID=96385441, Answer=3\n",
      "ID=96447635, Answer=4\n",
      "ID=96451423, Answer=4\n",
      "ID=96648059, Answer=3\n",
      "ID=96715271, Answer=3\n",
      "ID=96722195, Answer=4\n",
      "ID=96766603, Answer=3\n",
      "ID=96936128, Answer=3\n",
      "ID=97157258, Answer=3\n",
      "ID=97373138, Answer=2\n",
      "ID=97410704, Answer=2\n",
      "ID=97450729, Answer=2\n",
      "ID=97559200, Answer=1\n",
      "ID=97599133, Answer=4\n",
      "ID=97647301, Answer=3\n",
      "ID=97713655, Answer=3\n",
      "ID=97807607, Answer=2\n",
      "ID=98000175, Answer=3\n",
      "ID=98267927, Answer=4\n",
      "ID=98430210, Answer=4\n",
      "ID=98502966, Answer=1\n",
      "ID=98579961, Answer=2\n",
      "ID=98587143, Answer=2\n",
      "ID=98610949, Answer=3\n",
      "ID=98721567, Answer=4\n",
      "ID=98738485, Answer=3\n",
      "ID=98748827, Answer=3\n",
      "ID=99004971, Answer=4\n",
      "ID=99212436, Answer=1\n",
      "ID=99236758, Answer=2\n",
      "ID=99390631, Answer=3\n",
      "ID=99447882, Answer=4\n",
      "ID=99496052, Answer=4\n",
      "ID=99577046, Answer=3\n",
      "ID=99632910, Answer=2\n",
      "ID=99754201, Answer=4\n",
      "ID=99828105, Answer=4\n",
      "ID=99893610, Answer=3\n",
      "ID=99906994, Answer=3\n",
      "ID=99932833, Answer=2\n",
      "ID=99992286, Answer=4\n",
      "推理完成，答案已寫入 Kaggle-sample.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "import re\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "# ---------------------------\n",
    "# 1) 載入 微調後的模型 (base + LoRA)\n",
    "# ---------------------------\n",
    "base_model_name = \"shibing624/chinese-alpaca-plus-7b-hf\"\n",
    "lora_weights = \"lora-out\"  \n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(base_model_name)\n",
    "base_model = LlamaForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    load_in_8bit=True,  \n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, lora_weights, device_map=\"auto\")\n",
    "model.eval()\n",
    "\n",
    "def generate_prompt(instruction, input_text=\"\"):\n",
    "    return f\"\"\"請仔細閱讀以下文章，理解內容後，逐步排除選項，注意有些會有否定語句要思考仔細意思，並最終選擇最正確的答案。只需要回覆正確的數字選項 (1, 2, 3, 或 4)。\n",
    "\n",
    "            ### Instruction:\n",
    "            {instruction}\n",
    "\n",
    "            ### Input:\n",
    "            {input_text}\n",
    "\n",
    "            ### Response:\"\"\"\n",
    "\n",
    "def ask(instruction, input_text=\"\", max_new_tokens=16):\n",
    "    prompt = generate_prompt(instruction, input_text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    gen_config = GenerationConfig(\n",
    "        temperature=0.8,  # 提高隨機性\n",
    "        top_p=0.85,       # 降低累積概率閾值，生成更多多樣答案\n",
    "        num_beams=3,      # 使用多束搜索\n",
    "        max_new_tokens=max_new_tokens,\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(**inputs, generation_config=gen_config)\n",
    "\n",
    "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    raw_answer = output.split(\"### Response:\")[-1].strip()\n",
    "\n",
    "    numbers = re.findall(r\"[1234]\", raw_answer)\n",
    "\n",
    "    if numbers:\n",
    "        final_answer = numbers[0]\n",
    "    else:\n",
    "        final_answer = \"na\" \n",
    "\n",
    "    return final_answer\n",
    "\n",
    "# ---------------------------\n",
    "# 2) 讀取測試集，進行推理\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_excel(\"AI1000.xlsx\") \n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        q_id = row[\"題號\"] \n",
    "        article = str(row[\"文章\"]).strip()\n",
    "        question = str(row[\"問題\"]).strip()\n",
    "        option1 = str(row[\"選項1\"]).strip()\n",
    "        option2 = str(row[\"選項2\"]).strip()\n",
    "        option3 = str(row[\"選項3\"]).strip()\n",
    "        option4 = str(row[\"選項4\"]).strip()\n",
    "\n",
    "        # 組合成 input_text\n",
    "        # 你可以自行修改內容格式，只要跟模型溝通清楚即可\n",
    "        input_text = (\n",
    "            f\"【文章】{article}\\n\"\n",
    "            f\"【問題】{question}\\n\"\n",
    "            f\"【選項】\\n1) {option1}\\n2) {option2}\\n3) {option3}\\n4) {option4}\"\n",
    "        )\n",
    "\n",
    "        instruction = (\n",
    "            \"請仔細閱讀以下文章和問題，並比較每個選項的內容。\"\n",
    "            \"根據文章中的資訊，仔細想一想前後語句的邏輯，逐一排除不符合邏輯的選項，最後選擇最符合條件最高度正確的正確答案（1、2、3 或 4）。\"\n",
    "            \"請按照以下步驟進行：1. 閱讀文章，理解核心內容。2. 分析問題的含義，逐一比較選項。3. 排除不符合條件的選項。4. 清晰地給出 \\\"最終答案：\\\"。\"\n",
    "            \"有些題目會有雙重否定或是中文的語句差異，要注意這些小細節！\"\n",
    "            \"請注意，只允許輸出一個數字答案，並避免任何解釋或多餘的字符。\"\n",
    "        )\n",
    "\n",
    "        # 取得模型回答\n",
    "        answers = [ask(instruction, input_text, max_new_tokens=16) for _ in range(10)]\n",
    "        final_answer = max(set(answers), key=answers.count)  # 投票選出最多的答案\n",
    "\n",
    "        print(f\"ID={q_id}, Answer={final_answer}\")\n",
    "        results.append([q_id, final_answer])\n",
    "\n",
    "    # ---------------------------\n",
    "    # 3) 寫入 CSV 檔\n",
    "    # ---------------------------\n",
    "    with open(\"Kaggle-sample.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as fw:\n",
    "        writer = csv.writer(fw)\n",
    "        writer.writerow([\"ID\", \"Answer\"])\n",
    "        writer.writerows(results)\n",
    "\n",
    "    print(\"推理完成，答案已寫入 Kaggle-sample.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
